{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b51943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Critic Model ### \n",
    "class Critic(nn.Module):\n",
    "  def __init__(self, channels_img, feature_d):\n",
    "    super(Critic, self).__init__()\n",
    "    self.critic = nn.Sequential(\n",
    "        # Input image:  N * num_channnels * 64 * 64\n",
    "        nn.Conv2d(channels_img, feature_d, kernel_size=(4, 4), stride=(2,2), padding=(1, 1)), # image 32*32\n",
    "        nn.LeakyReLU(0.2),\n",
    "        self._block(feature_d, feature_d*2, 4, 2, 1), # feature size: 16 * 16\n",
    "        self._block(feature_d*2, feature_d*4, 4, 2, 1), # feature size: 8 * 8\n",
    "        self._block(feature_d*4, feature_d*8, 4, 2, 1), # feature size: 4 * 4\n",
    "        nn.Conv2d(feature_d*8, 1, kernel_size=(4,4), stride=(2,2), padding=0), # image 1*1*1 a single value to determine real or fake\n",
    "        #nn.Sigmoid(), # to be between [0,1], but we do not need it for WGAN bec it is unbounded in WGAN\n",
    "\n",
    "    )\n",
    "  \n",
    "  def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False), # Bias bec we use the batchnorm\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.critic(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a373639",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gen Model ### \n",
    "class Generator(nn.Module):\n",
    "  def __init__(self, z_dim, channels_img, feature_g):\n",
    "    super(Generator, self).__init__()\n",
    "    # Input image: batch * z_dim * 1 * 1\n",
    "    self.gen = nn.Sequential(\n",
    "        self._block(z_dim, feature_g*16, 4, 1, 0), # image : batch * (f_g * 16) * 4 * 4  \n",
    "        self._block(feature_g*16, feature_g*8, 4, 2, 1), # image : batch * (f_g * 8) * 8 * 8\n",
    "        self._block(feature_g*8, feature_g*4, 4, 2, 1), # image : batch * (f_g * 4) * 16 * 16\n",
    "        self._block(feature_g*4, feature_g*2, 4, 2, 1), # image : batch * (f_g * 2) * 32 * 32\n",
    "        nn.ConvTranspose2d(feature_g*2, channels_img, 4 ,2, 1), # # image : batch * (1) * 64 * 64\n",
    "        nn.Tanh(), # between [-1, 1]\n",
    "            )\n",
    "  \n",
    "  def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias= False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(),        \n",
    "    )  \n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.gen(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define  a function to initialize the weights\n",
    "def initialize_weights(model):\n",
    "  for m in model.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "      nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb979527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  N, C, H, W = 10, 3, 64, 64\n",
    "  z_dim = 100\n",
    "  x = torch.randn((N, C, H, W))\n",
    "  critic = Critic(C, 8)\n",
    "  initialize_weights(critic)\n",
    "  assert critic(x).shape == (N, 1, 1, 1)\n",
    "  gen = Generator(z_dim, C, 8)\n",
    "  initialize_weights(gen)\n",
    "  z = torch.randn((N, z_dim, 1, 1))\n",
    "  assert gen(z).shape == (N, C, H, W)\n",
    "  print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d89c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a36c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter setting\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 1e-4\n",
    "num_critic = 5\n",
    "LAMBDA = 10\n",
    "batch_size = 128\n",
    "image_size = 64\n",
    "channel_img = 1\n",
    "num_epoches = 5\n",
    "feature_disc = 16\n",
    "feature_gen = 16\n",
    "z_dim = 100\n",
    "Transforms = transforms.Compose([transforms.Resize(image_size),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.5 for _ in range(channel_img)], [0.5 for _ in range(channel_img)]),\n",
    "                                 ])\n",
    "## Data Loading\n",
    "train_dataset = datasets.MNIST(root=\"/.\", train=True, transform=Transforms, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3006e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "gen = Generator(z_dim, channel_img, feature_gen).to(device)\n",
    "critic = Critic(channel_img, feature_disc).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer setting\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=lr, betas=(0., 0.9))\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0., 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db57076",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5db6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "w = torch.rand(20,2,1,1, requires_grad=True)\n",
    "x = w**3\n",
    "y = x.repeat(20,1,64,64)\n",
    "gradient = torch.autograd.grad(outputs=y, inputs=w, grad_outputs=torch.ones_like(y), \n",
    "                               retain_graph=True, create_graph=True)[0]\n",
    "print(\"the Gradient shape is:\", gradient.shape)\n",
    "pp = gradient.view(gradient.shape[0], -1)\n",
    "print(\"the view shape is:\", pp.shape)\n",
    "\n",
    "N = pp.norm(2,1)\n",
    "print(\"the norm shape is:\", N.shape)\n",
    "\n",
    "gpp = torch.mean(N-1)\n",
    "print(gpp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771dc44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient penalty & 1-L norm satisfaction \n",
    "def gradient_penalty(critic, real, fake, device=\"cpu\"):\n",
    "    B,C, H, W = real.shape\n",
    "    Epsilon = torch.rand(B, 1, 1, 1).repeat(1, C, H, W)\n",
    "    Interpolate_image = Epsilon*real + (1-Epsilon)*fake\n",
    "    critic_score = critic(Interpolate_image)\n",
    "    \n",
    "    Grad = torch.autograd.grad(outputs = critic_score,\n",
    "                               inputs = Interpolate_image,\n",
    "                               grad_outputs = torch.ones_like(critic_score),\n",
    "                               retain_graph = True,\n",
    "                               create_graph = True)[0] # the output is tuple, the [0] helps to extract Tensors, \n",
    "                                                       # the gradient shape =inputs.shapee\n",
    "    \n",
    "    Grad = Grad.view(Grad.shape[0], -1) # reshape it to obtain norm 2 per sample \n",
    "    grad_norm = torch.mean(Grad.norm(2, dim = 1))\n",
    "    gp = (grad_norm - 1)**2\n",
    "    return gp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ae97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Process\n",
    "fixed_noise = torch.randn(batch_size, z_dim, 1, 1).to(device=device) # used for Tensorboard\n",
    "Write_real = SummaryWriter(f\"Logs/real\")\n",
    "Writer_fake = SummaryWriter(f\"Logs/fake\")\n",
    "step = 0\n",
    "\n",
    "gen.train()\n",
    "critic.train()\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    for batch_idx, (real, _) in enumerate(train_loader):\n",
    "\n",
    "        # Train critic\n",
    "        for t in range(num_critic):\n",
    "            real = real.to(device=device)\n",
    "            noise = torch.randn((batch_size, z_dim, 1, 1)).to(device=device)\n",
    "            fake = gen(noise)\n",
    "\n",
    "            critic_fake = critic(fake).view(-1)\n",
    "            critic_real = critic(real).view(-1)\n",
    "            \n",
    "\n",
    "            gp = gradient_penalty(critic, real, fake, device=device)\n",
    "            Loss_critic = -((torch.mean(critic_fake) - torch.mean(critic_real)) + LAMBDA*gp) \n",
    "            critic.zero_grad()\n",
    "            Loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "\n",
    "        # Train Generator  Max {E[D(G(x)))] \n",
    "        gen_fake = critic(fake).view(-1)\n",
    "        Loss_gen = -torch.mean(gen_fake)\n",
    "        gen.zero_grad()\n",
    "        Loss_gen.backward(retain_graph=True)\n",
    "        opt_gen.step()\n",
    "\n",
    "     # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 2 == 0 and batch_idx > 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epoches}] Batch {batch_idx}/{len(train_loader)} \\\n",
    "                Loss D: {Loss_critic:.4f}, loss G: {Loss_gen:.4f}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                        # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "\n",
    "                Write_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                Writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f320738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
